{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34a3b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/connectome/jubin/ABCD-3DCNN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c32674f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/scratch/connectome/jubin/ABCD-3DCNN/STEP_5_Transfer_learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc4c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ======= load module ======= ##\n",
    "from utils.utils import argument_setting, select_model, save_exp_result, checkpoint_load #  \n",
    "from dataloaders.dataloaders import make_dataset\n",
    "from dataloaders.preprocessing import preprocessing_cat, preprocessing_num\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import argparse \n",
    "from tqdm.auto import tqdm ##progress\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "def test(net,partition,args):    \n",
    "    testloader = torch.utils.data.DataLoader(partition['test'],\n",
    "                                            batch_size=args.test_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)\n",
    "\n",
    "    net.eval()\n",
    "    if hasattr(net, 'module'):\n",
    "        device = net.device_ids[0]\n",
    "    else: \n",
    "        if args.sbatch =='True':\n",
    "            device = 'cuda:0'\n",
    "        else:\n",
    "            device = f'cuda:{args.gpus[0]}'\n",
    "    #correct = {}\n",
    "    #y_true = {}\n",
    "    \n",
    "    outputs = {}\n",
    "    y_true = {}\n",
    "    test_acc = {}\n",
    "    confusion_matrices = {}\n",
    "\n",
    "\n",
    "    if args.cat_target:\n",
    "        for cat_target in args.cat_target:\n",
    "            outputs[cat_target] = torch.tensor([])\n",
    "            y_true[cat_target] = torch.tensor([])\n",
    "            test_acc[cat_target] = []\n",
    "\n",
    "    if args.num_target:\n",
    "        for num_target in args.num_target:\n",
    "            outputs[num_target] = torch.tensor([])\n",
    "            y_true[num_target] = torch.tensor([])\n",
    "            test_acc[num_target] = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(testloader),0):\n",
    "            image, targets = data\n",
    "            image = image.to(device)\n",
    "\n",
    "            output = net(image)\n",
    "            if args.cat_target:\n",
    "                for cat_target in args.cat_target:\n",
    "                    outputs[cat_target] = torch.cat((outputs[cat_target], output[cat_target].cpu()))\n",
    "                    y_true[cat_target] = torch.cat((y_true[cat_target], targets[cat_target].cpu()))\n",
    "\n",
    "            if args.num_target:\n",
    "                for num_target in args.num_target:\n",
    "                    outputs[num_target] = torch.cat((outputs[num_target], output[num_target].cpu()))\n",
    "                    y_true[num_target] = torch.cat((y_true[num_target], targets[num_target].cpu()))\n",
    "\n",
    "    \n",
    "    # caculating ACC and R2 at once  \n",
    "    if args.cat_target:\n",
    "        for cat_target in args.cat_target:\n",
    "            _, predicted = torch.max(outputs[cat_target].data,1)\n",
    "            correct = (predicted == y_true[cat_target]).sum().item()\n",
    "            total = y_true[cat_target].size(0)\n",
    "            test_acc[cat_target].append(100 * (correct / total))\n",
    "\n",
    "            if args.confusion_matrix:\n",
    "                for label_cm in args.confusion_matrix: \n",
    "                    if len(np.unique(y_true[cat_target].numpy())) == 2:\n",
    "                        confusion_matrices[label_cm] = {}\n",
    "                        confusion_matrices[label_cm]['True Positive'] = 0\n",
    "                        confusion_matrices[label_cm]['True Negative'] = 0\n",
    "                        confusion_matrices[label_cm]['False Positive'] = 0\n",
    "                        confusion_matrices[label_cm]['False Negative'] = 0\n",
    "                        if label_cm == cat_target:\n",
    "                            tn, fp, fn, tp = confusion_matrix(y_true[cat_target].numpy(), predicted.numpy()).ravel()\n",
    "                            confusion_matrices[label_cm]['True Positive'] = int(tp)\n",
    "                            confusion_matrices[label_cm]['True Negative'] = int(tn)\n",
    "                            confusion_matrices[label_cm]['False Positive'] = int(fp)\n",
    "                            confusion_matrices[label_cm]['False Negative'] = int(fn)                       \n",
    "\n",
    "\n",
    "    if args.num_target:\n",
    "        for num_target in args.num_target:\n",
    "            predicted =  outputs[num_target].float()\n",
    "            criterion = nn.MSELoss()\n",
    "            loss = criterion(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "            l1loss = nn.L1Loss()\n",
    "            MAE = l1loss(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "            y_var = torch.var(y_true[num_target])\n",
    "            r_square = 1 - (loss / y_var)\n",
    "            test_acc[num_target].append(r_square.item())\n",
    "            confusion_matrices = None\n",
    "\n",
    "    return test_acc, confusion_matrices, MAE\n",
    "    \n",
    "## ========= Experiment =============== ##\n",
    "def experiment(partition, subject_data, save_dir, args): #in_channels,out_dim\n",
    "    \n",
    "    # selecting a model\n",
    "    net = select_model(subject_data, args) #  \n",
    "    \n",
    "    # loading pretrained model if transfer option is given\n",
    "    if args.load:\n",
    "        print(\"*** Model setting for test *** \\n\")\n",
    "        model_dir = glob.glob(f'/scratch/connectome/jubin/result/model/*{args.load}*')[0]\n",
    "        print(f\"Loaded {args.load}\")\n",
    "        net = checkpoint_load(net, model_dir)\n",
    "    elif args.load == '':\n",
    "        print(\"Warning: Invalid model selection\")\n",
    "        sys.exit()\n",
    "    \n",
    "    # setting a DataParallel and model on GPU\n",
    "    if args.sbatch == \"True\":\n",
    "        devices = []\n",
    "        for d in range(torch.cuda.device_count()):\n",
    "            devices.append(d)\n",
    "        net = nn.DataParallel(net, device_ids = devices)\n",
    "    else:\n",
    "        if not args.gpus:\n",
    "            raise ValueError(\"GPU DEVICE IDS SHOULD BE ASSIGNED\")\n",
    "        else:\n",
    "            net = nn.DataParallel(net, device_ids=args.gpus)\n",
    "            \n",
    "    if args.sbatch == 'True':\n",
    "        net.cuda()\n",
    "    else:\n",
    "        net.to(f'cuda:{args.gpus[0]}')\n",
    "        \n",
    "    test_acc, confusion_matrices, MAE = test(net, partition, args)\n",
    "    \n",
    "    result = {'test_acc':test_acc,'MAE':MAE}\n",
    "    \n",
    "    print(f\"Test result: {test_acc} & {MAE} for {args.load}\") \n",
    "    \n",
    "    if confusion_matrices != None:\n",
    "        result['confusion_matrices'] = confusion_matrices\n",
    "        \n",
    "    return vars(args), result\n",
    "## ==================================== ##\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    ## ========= Setting ========= ##\n",
    "    # seed number\n",
    "    seed = 1234\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d6bc39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--filter'], dest='filter', nargs='+', const=None, default=[], type=None, choices=None, help='options for filter data by phenotype. usage: --filter abcd_site:10 sex:1', metavar=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"--model\",required=True,type=str,help='',choices=['simple3D','vgg3D11','vgg3D13','vgg3D16','vgg3D19','resnet3D50','resnet3D101','resnet3D152', 'densenet3D121', 'densenet3D169','densenet201','densenet264'])\n",
    "parser.add_argument(\"--dataset\",required=True, type=str, choices=['UKB','ABCD'],help='') # revising\n",
    "parser.add_argument(\"--data\", type=str, help='select data type') # revising\n",
    "parser.add_argument(\"--val_size\",default=0.1,type=float,required=False,help='')\n",
    "parser.add_argument(\"--test_size\",default=0.1,type=float,required=False,help='')\n",
    "parser.add_argument(\"--resize\",default=(96, 96, 96),type=int,nargs=\"*\",required=False,help='')\n",
    "parser.add_argument(\"--train_batch_size\",default=16,type=int,required=False,help='')\n",
    "parser.add_argument(\"--val_batch_size\",default=16,type=int,required=False,help='')\n",
    "parser.add_argument(\"--test_batch_size\",default=1,type=int,required=False,help='')\n",
    "parser.add_argument(\"--in_channels\",default=1,type=int,required=False,help='')\n",
    "parser.add_argument(\"--optim\",type=str,required=True,help='', choices=['Adam','SGD','RAdam','AdamW'])\n",
    "parser.add_argument(\"--scheduler\",type=str,default='',help='') # revising\n",
    "parser.add_argument(\"--early_stopping\",type=int,default=None,help='') # revising\n",
    "parser.add_argument(\"--lr\", default=0.01,type=float,required=False,help='')\n",
    "parser.add_argument(\"--lr_adjust\", default=0.01, type=float, required=False,help='')   \n",
    "parser.add_argument(\"--weight_decay\",default=0.001,type=float,required=False,help='')\n",
    "parser.add_argument(\"--epoch\",type=int,required=True,help='')\n",
    "parser.add_argument(\"--epoch_FC\",type=int,required=False,default=0,help='')\n",
    "parser.add_argument(\"--exp_name\",type=str,required=True,help='')\n",
    "parser.add_argument(\"--cat_target\", type=str, nargs='*', required=False, help='')\n",
    "parser.add_argument(\"--num_target\", type=str,nargs='*', required=False, help='')\n",
    "parser.add_argument(\"--confusion_matrix\", type=str, nargs='*',required=False, help='')\n",
    "parser.add_argument(\"--gpus\", type=int,nargs='*', required=False, help='')\n",
    "parser.add_argument(\"--sbatch\", type=str, required=False, choices=['True', 'False'])\n",
    "parser.add_argument(\"--transfer\", type=str, required=False, default=\"\", choices=['sex','age','simclr','MAE'])\n",
    "parser.add_argument(\"--unfrozen_layer\", type=str, required=False, default='0') \n",
    "parser.add_argument(\"--load\", type=str, required=False, default=\"\")\n",
    "parser.add_argument(\"--init_unfrozen\", type=str, required=False, default=\"\",help='init unfrozen layers')\n",
    "parser.add_argument(\"--scratch\", type=str, required=False, default='',help='option for learning from scratch')\n",
    "parser.add_argument(\"--filter\",required=False, nargs=\"+\", default=[],\n",
    "                    help='options for filter data by phenotype. usage: --filter abcd_site:10 sex:1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7abb9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = '--load TL_age_MAE_ABCD_04_3647d8 --num_target age --dataset ABCD --data freesurfer --model densenet3D121 --resize 96 96 96 --gpus 0 --test_batch_size 128 --val_size 0.1 --test_size 0.1 --exp_name TL_age_MAE_ABCD_04_3647d8 --optim AdamW --epoch 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0e4d2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Categorical target labels are None and Numerical target labels are ['age'] *** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(com.split())\n",
    "print(\"*** Categorical target labels are {} and Numerical target labels are {} *** \\n\".format(\n",
    "    args.cat_target, args.num_target)\n",
    "     )\n",
    "\n",
    "if not args.cat_target:\n",
    "    args.cat_target = []\n",
    "elif not args.num_target:\n",
    "    args.num_target = []\n",
    "elif not args.cat_target and args.num_target:\n",
    "    raise ValueError('YOU SHOULD SELECT THE TARGET!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83e80b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 11357/11357 [00:00<00:00, 98103.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects=11357, train=9085, val=1135, test=1135\n",
      "*** Making a dataset is completed *** \n",
      "\n",
      "*** Test for TL_age_MAE_ABCD_04_3647d8 Start ***\n",
      "*** Model setting for test *** \n",
      "\n",
      "Loaded TL_age_MAE_ABCD_04_3647d8\n",
      "The best checkpoint is loaded\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## ========= Run Experiment and saving result ========= ## \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run Experiment\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Test for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mexp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Start ***\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m setting, result \u001b[38;5;241m=\u001b[39m \u001b[43mexperiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Save result\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#save_exp_result(save_dir, setting, result)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*** Experiment Done ***\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mexperiment\u001b[0;34m(partition, subject_data, save_dir, args)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU DEVICE IDS SHOULD BE ASSIGNED\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m         net \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39msbatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    141\u001b[0m     net\u001b[38;5;241m.\u001b[39mcuda()\n",
      "File \u001b[0;32m~/.conda/envs/3DCNN/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:145\u001b[0m, in \u001b[0;36mDataParallel.__init__\u001b[0;34m(self, module, device_ids, output_device, dim)\u001b[0m\n\u001b[1;32m    142\u001b[0m _check_balance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_device_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/3DCNN/lib/python3.9/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/3DCNN/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/3DCNN/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/3DCNN/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.conda/envs/3DCNN/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "if args.transfer in ['age','MAE']:\n",
    "    assert 96 in args.resize, \"age(MSE/MAE) transfer model's resize should be 96\"\n",
    "elif args.transfer == 'sex':\n",
    "    assert 80 in args.resize, \"sex transfer model's resize should be 80\"\n",
    "\n",
    "save_dir = os.getcwd() + '/result'\n",
    "partition, subject_data = make_dataset(args)  \n",
    "\n",
    "## ========= Run Experiment and saving result ========= ## \n",
    "\n",
    "# Run Experiment\n",
    "print(f\"*** Test for {args.exp_name} Start ***\")\n",
    "setting, result = experiment(partition, subject_data, save_dir, deepcopy(args))\n",
    "\n",
    "# Save result\n",
    "#save_exp_result(save_dir, setting, result)\n",
    "print(\"*** Experiment Done ***\\n\")\n",
    "## ====================================== ##\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e001d66",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "torch.Tensor(1).cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
