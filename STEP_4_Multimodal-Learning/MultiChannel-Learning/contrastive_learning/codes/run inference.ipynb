{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34a3b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/connectome/jubin/ABCD-3DCNN/STEP_4_Multimodal-Learning/MultiChannel-Learning/contrastive_learning/codes'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32674f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codes',\n",
       " 'README.md',\n",
       " 'envs',\n",
       " '__pycache__',\n",
       " 'run_contrastive_learning.py',\n",
       " 'models',\n",
       " 'result',\n",
       " 'test.py',\n",
       " 'dataloaders',\n",
       " 'utils',\n",
       " '.ipynb_checkpoints']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc4c46f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/connectome/jubin/.conda/envs/3DCNN/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## ======= load module ======= ##\n",
    "from utils.utils import argument_setting, select_model, save_exp_result, checkpoint_load #  \n",
    "from dataloaders.dataloaders import make_dataset\n",
    "from dataloaders.preprocessing import preprocessing_cat, preprocessing_num\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import argparse \n",
    "from tqdm.auto import tqdm ##progress\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    ## ========= Setting ========= ##\n",
    "    # seed number\n",
    "    seed = 1234\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6bc39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--init_unfrozen'], dest='init_unfrozen', nargs=None, const=None, default='', type=<class 'str'>, choices=None, help='Initializes unfrozen layers', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Options for model setting\n",
    "parser.add_argument(\"--model\", type=str, required=True, help='Select model. e.g. densenet3D121, sfcn.',\n",
    "                    choices=['simple3D', 'sfcn', 'vgg3D11', 'vgg3D13', 'vgg3D16', 'vgg3D19',\n",
    "                             'resnet3D50', 'resnet3D101', 'resnet3D152',\n",
    "                             'densenet3D121', 'densenet3D169', 'densenet201', 'densenet264'])\n",
    "parser.add_argument(\"--in_channels\", default=1, type=int, help='')\n",
    "\n",
    "# Options for dataset and data type, split ratio, CV, resize, augmentation\n",
    "parser.add_argument(\"--dataset\", type=str, choices=['UKB','ABCD'], required=True, help='Selelct dataset')\n",
    "parser.add_argument(\"--data_type\", nargs='+', type=str, help='Select data type(sMRI, dMRI)',\n",
    "                    choices=['fmriprep', 'freesurfer', 'FA_unwarpped_nii', 'FA_warpped_nii',\n",
    "                             'MD_unwarpped_nii', 'MD_warpped_nii', 'RD_unwarpped_nii', 'RD_warpped_nii'])\n",
    "parser.add_argument(\"--val_size\", default=0.1, type=float, help='')\n",
    "parser.add_argument(\"--test_size\", default=0.1, type=float, help='')\n",
    "parser.add_argument(\"--cv\", default=None, type=int, choices=[1,2,3,4,5], help=\"option for 5-fold CV. 1~5.\")\n",
    "parser.add_argument(\"--resize\", nargs=\"*\", default=(96, 96, 96), type=int, help='')\n",
    "parser.add_argument(\"--augmentation\", nargs=\"*\", default=[], type=str, choices=['shift','flip'],\n",
    "                    help=\"Data augmentation - [shift, flip] are available\")\n",
    "\n",
    "# Hyperparameters for model training\n",
    "parser.add_argument(\"--lr\", default=0.01, type=float, help='')\n",
    "parser.add_argument(\"--lr_adjust\", default=0.01, type=float, help='')\n",
    "parser.add_argument(\"--epoch\", type=int, required=True, help='')\n",
    "parser.add_argument(\"--epoch_FC\", type=int, default=0, help='Option for training only FC layer')\n",
    "parser.add_argument(\"--optim\", default='Adam', type=str, choices=['Adam','SGD','RAdam','AdamW'], help='')\n",
    "parser.add_argument(\"--weight_decay\", default=0.001, type=float, help='')\n",
    "parser.add_argument(\"--scheduler\", default='', type=str, help='') \n",
    "parser.add_argument(\"--early_stopping\", default=None, type=int, help='')\n",
    "parser.add_argument(\"--train_batch_size\", default=16, type=int, help='')\n",
    "parser.add_argument(\"--val_batch_size\", default=16, type=int, help='')\n",
    "parser.add_argument(\"--test_batch_size\", default=1, type=int, help='')\n",
    "\n",
    "# Options for experiment setting\n",
    "parser.add_argument(\"--exp_name\", type=str, required=True, help='')\n",
    "parser.add_argument(\"--gpus\", nargs='+', type=int, help='')\n",
    "parser.add_argument(\"--sbatch\", type=str, choices=['True', 'False'])\n",
    "parser.add_argument(\"--cat_target\", nargs='+', default=[], type=str, help='')\n",
    "parser.add_argument(\"--num_target\", nargs='+', default=[], type=str, help='')\n",
    "parser.add_argument(\"--confusion_matrix\",  nargs='*', type=str, help='')\n",
    "parser.add_argument(\"--filter\", nargs=\"*\", default=[], type=str,\n",
    "                    help='options for filter data by phenotype. usage: --filter abcd_site:10 sex:1')\n",
    "parser.add_argument(\"--load\", default='', type=str, help='Load model weight that mathces {your_exp_dir}/result/*{load}*')\n",
    "parser.add_argument(\"--scratch\", default='', type=str, help='Option for learning from scratch')\n",
    "parser.add_argument(\"--transfer\", default='', type=str, choices=['sex','age','simclr','MAE'],\n",
    "                    help='Choose pretrained model according to your option')\n",
    "parser.add_argument(\"--unfrozen_layer\", default='0', type=str, help='Select the number of layers that would be unfrozen')\n",
    "parser.add_argument(\"--init_unfrozen\", default='', type=str, help='Initializes unfrozen layers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e57a28dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for adhd\n",
    "com = '--cat_target Attention.Deficit.Hyperactivity.Disorder.x --dataset ABCD --data_type freesurfer MD_warpped_nii --model sfcn --resize 80 80 80 --gpus 0 1 --test_batch_size 1 --val_size 0.1 --test_size 0.1 --exp_name adhd_test --optim AdamW --epoch 1 --confusion_matrix sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abb9fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = '--cv 5 --load SFCNSC_11 --cat_target sex --dataset ABCD --data freesurfer --model sfcn --resize 80 80 80 --gpus 0 --test_batch_size 1 --val_size 0.1 --test_size 0.1 --exp_name SFCNSC_11test --optim AdamW --epoch 0 --confusion_matrix sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e188268",
   "metadata": {},
   "outputs": [],
   "source": [
    "com = '--cat_target sex --dataset ABCD --data freesurfer --model sfcn --resize 80 80 80 --gpus 0 --test_batch_size 128 --val_size 0.1 --test_size 0.1 --exp_name sfcn_test --optim AdamW --epoch 0 --confusion_matrix sex'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0e4d2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Categorical target labels are ['Attention.Deficit.Hyperactivity.Disorder.x'] and Numerical target labels are [] *** \n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args(com.split())\n",
    "print(\"*** Categorical target labels are {} and Numerical target labels are {} *** \\n\".format(\n",
    "    args.cat_target, args.num_target)\n",
    "     )\n",
    "\n",
    "if not args.cat_target:\n",
    "    args.cat_target = []\n",
    "elif not args.num_target:\n",
    "    args.num_target = []\n",
    "elif not args.cat_target and args.num_target:\n",
    "    raise ValueError('YOU SHOULD SELECT THE TARGET!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83e80b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       NDARINV00BD7VDC\n",
      "1       NDARINV00CY2MDM\n",
      "2       NDARINV00LJVZK2\n",
      "3       NDARINV00U4FTRU\n",
      "4       NDARINV014RTM1V\n",
      "             ...       \n",
      "3986    NDARINVV5MHL75K\n",
      "3987    NDARINVV5XX9GEF\n",
      "3988    NDARINVV6KFJX12\n",
      "3989    NDARINVV6MZ4VB1\n",
      "3990    NDARINVV6NAXTR2\n",
      "Name: subjectkey, Length: 3991, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3991/3991 [00:00<00:00, 84888.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects=3991, train=3193, val=399, test=399\n",
      "In train dataset, Attention.Deficit.Hyperactivity.Disorder.x contains 1393 CASE and 1800 CONTROL\n",
      "In validation dataset, Attention.Deficit.Hyperactivity.Disorder.x contains 183 CASE and 216 CONTROL\n",
      "In test dataset, Attention.Deficit.Hyperactivity.Disorder.x contains 160 CASE and 239 CONTROL\n",
      "*** Making a dataset is completed *** \n",
      "\n",
      "*** Test for adhd_test Start ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 399/399 [01:45<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result: {'Attention.Deficit.Hyperactivity.Disorder.x': [55.388471177944865]} & None for \n"
     ]
    }
   ],
   "source": [
    "if args.transfer in ['age','MAE']:\n",
    "    assert 96 in args.resize, \"age(MSE/MAE) transfer model's resize should be 96\"\n",
    "elif args.transfer == 'sex':\n",
    "    assert 80 in args.resize, \"sex transfer model's resize should be 80\"\n",
    "\n",
    "save_dir = os.getcwd() + '/result'\n",
    "partition, subject_data = make_dataset(args,args.data_type[1])  \n",
    "\n",
    "## ========= Run Experiment and saving result ========= ## \n",
    "\n",
    "# Run Experiment\n",
    "print(f\"*** Test for {args.exp_name} Start ***\")\n",
    "net = select_model(subject_data, args) #  \n",
    "\n",
    "# loading pretrained model if transfer option is given\n",
    "if args.load:\n",
    "    print(\"*** Model setting for test *** \\n\")\n",
    "    model_dir = glob.glob(f'/scratch/connectome/jubin/result/model/*{args.load}*')[0]\n",
    "    print(f\"Loaded {args.load}\")\n",
    "    net = checkpoint_load(net, model_dir)\n",
    "\n",
    "# setting a DataParallel and model on GPU\n",
    "if args.sbatch == \"True\":\n",
    "    devices = []\n",
    "    for d in range(torch.cuda.device_count()):\n",
    "        devices.append(d)\n",
    "    net = nn.DataParallel(net, device_ids = devices)\n",
    "else:\n",
    "    if not args.gpus:\n",
    "        raise ValueError(\"GPU DEVICE IDS SHOULD BE ASSIGNED\")\n",
    "    else:\n",
    "        net = nn.DataParallel(net, device_ids=args.gpus)\n",
    "\n",
    "if args.sbatch == 'True':\n",
    "    net.cuda()\n",
    "else:\n",
    "    net.to(f'cuda:{args.gpus[0]}')\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(partition['test'],\n",
    "                                            batch_size=args.test_batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)\n",
    "\n",
    "net.eval()\n",
    "if hasattr(net, 'module'):\n",
    "    device = net.device_ids[0]\n",
    "else: \n",
    "    if args.sbatch =='True':\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = f'cuda:{args.gpus[0]}'\n",
    "#correct = {}\n",
    "#y_true = {}\n",
    "\n",
    "outputs = {}\n",
    "y_true = {}\n",
    "test_acc = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "\n",
    "if args.cat_target:\n",
    "    for cat_target in args.cat_target:\n",
    "        outputs[cat_target] = torch.tensor([])\n",
    "        y_true[cat_target] = torch.tensor([])\n",
    "        test_acc[cat_target] = []\n",
    "\n",
    "if args.num_target:\n",
    "    for num_target in args.num_target:\n",
    "        outputs[num_target] = torch.tensor([])\n",
    "        y_true[num_target] = torch.tensor([])\n",
    "        test_acc[num_target] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(testloader),0):\n",
    "        image, targets = data\n",
    "        image = image.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        if args.cat_target:\n",
    "            for cat_target in args.cat_target:\n",
    "                outputs[cat_target] = torch.cat((outputs[cat_target], output[cat_target].cpu()))\n",
    "                y_true[cat_target] = torch.cat((y_true[cat_target], targets[cat_target].cpu()))\n",
    "\n",
    "        if args.num_target:\n",
    "            for num_target in args.num_target:\n",
    "                outputs[num_target] = torch.cat((outputs[num_target], output[num_target].cpu()))\n",
    "                y_true[num_target] = torch.cat((y_true[num_target], targets[num_target].cpu()))\n",
    "\n",
    "\n",
    "# caculating ACC and R2 at once  \n",
    "if args.cat_target:\n",
    "    for cat_target in args.cat_target:\n",
    "        _, predicted = torch.max(outputs[cat_target].data,1)\n",
    "        correct = (predicted == y_true[cat_target]).sum().item()\n",
    "        total = y_true[cat_target].size(0)\n",
    "        test_acc[cat_target].append(100 * (correct / total))\n",
    "\n",
    "        if args.confusion_matrix:\n",
    "            for label_cm in args.confusion_matrix: \n",
    "                if len(np.unique(y_true[cat_target].numpy())) == 2:\n",
    "                    confusion_matrices[label_cm] = {}\n",
    "                    confusion_matrices[label_cm]['True Positive'] = 0\n",
    "                    confusion_matrices[label_cm]['True Negative'] = 0\n",
    "                    confusion_matrices[label_cm]['False Positive'] = 0\n",
    "                    confusion_matrices[label_cm]['False Negative'] = 0\n",
    "                    if label_cm == cat_target:\n",
    "                        tn, fp, fn, tp = confusion_matrix(y_true[cat_target].numpy(), predicted.numpy()).ravel()\n",
    "                        confusion_matrices[label_cm]['True Positive'] = int(tp)\n",
    "                        confusion_matrices[label_cm]['True Negative'] = int(tn)\n",
    "                        confusion_matrices[label_cm]['False Positive'] = int(fp)\n",
    "                        confusion_matrices[label_cm]['False Negative'] = int(fn)                       \n",
    "\n",
    "MAE = None\n",
    "if args.num_target:\n",
    "    for num_target in args.num_target:\n",
    "        predicted =  outputs[num_target].float()\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "        l1loss = nn.L1Loss()\n",
    "        MAE = l1loss(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "        y_var = torch.var(y_true[num_target])\n",
    "        r_square = 1 - (loss / y_var)\n",
    "        test_acc[num_target].append(r_square.item())\n",
    "        confusion_matrices = None\n",
    "\n",
    "result = {'test_acc':test_acc,'MAE':MAE}\n",
    "\n",
    "print(f\"Test result: {test_acc} & {MAE} for {args.load}\") \n",
    "\n",
    "if confusion_matrices != None:\n",
    "    result['confusion_matrices'] = confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfeb000c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 80, 80, 80])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2442b8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 1.6139065983869547}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition['train'].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3dbd16ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ad91878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sex': tensor([1., 1., 1.,  ..., 0., 0., 1.], dtype=torch.float64)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abe59ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'True Positive': 545,\n",
       " 'True Negative': 0,\n",
       " 'False Positive': 591,\n",
       " 'False Negative': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrices['sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd544db7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1136"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(torch.max(outputs['sex'].data,1)[1] == y_true['sex'])\n",
    "len(y_true['sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7048cbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [01:25<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result: {'sex': [98.94273127753304]} & None for ABCD_sex_TL_ALL_11_3bb9ad\n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(partition['val'], batch_size=args.test_batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "outputs = {}\n",
    "y_true = {}\n",
    "test_acc = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "\n",
    "if args.cat_target:\n",
    "    for cat_target in args.cat_target:\n",
    "        outputs[cat_target] = torch.tensor([])\n",
    "        y_true[cat_target] = torch.tensor([])\n",
    "        test_acc[cat_target] = []\n",
    "\n",
    "if args.num_target:\n",
    "    for num_target in args.num_target:\n",
    "        outputs[num_target] = torch.tensor([])\n",
    "        y_true[num_target] = torch.tensor([])\n",
    "        test_acc[num_target] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(testloader),0):\n",
    "        image, targets = data\n",
    "        image = image.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        if args.cat_target:\n",
    "            for cat_target in args.cat_target:\n",
    "                outputs[cat_target] = torch.cat((outputs[cat_target], output[cat_target].cpu()))\n",
    "                y_true[cat_target] = torch.cat((y_true[cat_target], targets[cat_target].cpu()))\n",
    "\n",
    "        if args.num_target:\n",
    "            for num_target in args.num_target:\n",
    "                outputs[num_target] = torch.cat((outputs[num_target], output[num_target].cpu()))\n",
    "                y_true[num_target] = torch.cat((y_true[num_target], targets[num_target].cpu()))\n",
    "\n",
    "\n",
    "# caculating ACC and R2 at once  \n",
    "if args.cat_target:\n",
    "    for cat_target in args.cat_target:\n",
    "        _, predicted = torch.max(outputs[cat_target].data,1)\n",
    "        correct = (predicted == y_true[cat_target]).sum().item()\n",
    "        total = y_true[cat_target].size(0)\n",
    "        test_acc[cat_target].append(100 * (correct / total))\n",
    "\n",
    "        if args.confusion_matrix:\n",
    "            for label_cm in args.confusion_matrix: \n",
    "                if len(np.unique(y_true[cat_target].numpy())) == 2:\n",
    "                    confusion_matrices[label_cm] = {}\n",
    "                    confusion_matrices[label_cm]['True Positive'] = 0\n",
    "                    confusion_matrices[label_cm]['True Negative'] = 0\n",
    "                    confusion_matrices[label_cm]['False Positive'] = 0\n",
    "                    confusion_matrices[label_cm]['False Negative'] = 0\n",
    "                    if label_cm == cat_target:\n",
    "                        tn, fp, fn, tp = confusion_matrix(y_true[cat_target].numpy(), predicted.numpy()).ravel()\n",
    "                        confusion_matrices[label_cm]['True Positive'] = int(tp)\n",
    "                        confusion_matrices[label_cm]['True Negative'] = int(tn)\n",
    "                        confusion_matrices[label_cm]['False Positive'] = int(fp)\n",
    "                        confusion_matrices[label_cm]['False Negative'] = int(fn)                       \n",
    "\n",
    "MAE = None\n",
    "if args.num_target:\n",
    "    for num_target in args.num_target:\n",
    "        predicted =  outputs[num_target].float()\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "        l1loss = nn.L1Loss()\n",
    "        MAE = l1loss(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "        y_var = torch.var(y_true[num_target])\n",
    "        r_square = 1 - (loss / y_var)\n",
    "        test_acc[num_target].append(r_square.item())\n",
    "        confusion_matrices = None\n",
    "\n",
    "result = {'test_acc':test_acc,'MAE':MAE}\n",
    "\n",
    "print(f\"Test result: {test_acc} & {MAE} for {args.load}\") \n",
    "\n",
    "if confusion_matrices != None:\n",
    "    result['confusion_matrices'] = confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646f4bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 36/36 [07:27<00:00, 12.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test result: {'sex': [98.66754762691333]} & None for ABCD_sex_TL_ALL_11_3bb9ad\n"
     ]
    }
   ],
   "source": [
    "testloader = torch.utils.data.DataLoader(partition['train'], batch_size=256, shuffle=False, num_workers=4)\n",
    "\n",
    "outputs = {}\n",
    "y_true = {}\n",
    "test_acc = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "\n",
    "if args.cat_target:\n",
    "    for cat_target in args.cat_target:\n",
    "        outputs[cat_target] = torch.tensor([])\n",
    "        y_true[cat_target] = torch.tensor([])\n",
    "        test_acc[cat_target] = []\n",
    "\n",
    "if args.num_target:\n",
    "    for num_target in args.num_target:\n",
    "        outputs[num_target] = torch.tensor([])\n",
    "        y_true[num_target] = torch.tensor([])\n",
    "        test_acc[num_target] = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(tqdm(testloader),0):\n",
    "        image, targets = data\n",
    "        image = image.to(device)\n",
    "\n",
    "        output = net(image)\n",
    "        if args.cat_target:\n",
    "            for cat_target in args.cat_target:\n",
    "                outputs[cat_target] = torch.cat((outputs[cat_target], output[cat_target].cpu()))\n",
    "                y_true[cat_target] = torch.cat((y_true[cat_target], targets[cat_target].cpu()))\n",
    "\n",
    "        if args.num_target:\n",
    "            for num_target in args.num_target:\n",
    "                outputs[num_target] = torch.cat((outputs[num_target], output[num_target].cpu()))\n",
    "                y_true[num_target] = torch.cat((y_true[num_target], targets[num_target].cpu()))\n",
    "\n",
    "\n",
    "# caculating ACC and R2 at once  \n",
    "if args.cat_target:\n",
    "    for cat_target in args.cat_target:\n",
    "        _, predicted = torch.max(outputs[cat_target].data,1)\n",
    "        correct = (predicted == y_true[cat_target]).sum().item()\n",
    "        total = y_true[cat_target].size(0)\n",
    "        test_acc[cat_target].append(100 * (correct / total))\n",
    "\n",
    "        if args.confusion_matrix:\n",
    "            for label_cm in args.confusion_matrix: \n",
    "                if len(np.unique(y_true[cat_target].numpy())) == 2:\n",
    "                    confusion_matrices[label_cm] = {}\n",
    "                    confusion_matrices[label_cm]['True Positive'] = 0\n",
    "                    confusion_matrices[label_cm]['True Negative'] = 0\n",
    "                    confusion_matrices[label_cm]['False Positive'] = 0\n",
    "                    confusion_matrices[label_cm]['False Negative'] = 0\n",
    "                    if label_cm == cat_target:\n",
    "                        tn, fp, fn, tp = confusion_matrix(y_true[cat_target].numpy(), predicted.numpy()).ravel()\n",
    "                        confusion_matrices[label_cm]['True Positive'] = int(tp)\n",
    "                        confusion_matrices[label_cm]['True Negative'] = int(tn)\n",
    "                        confusion_matrices[label_cm]['False Positive'] = int(fp)\n",
    "                        confusion_matrices[label_cm]['False Negative'] = int(fn)                       \n",
    "\n",
    "MAE = None\n",
    "if args.num_target:\n",
    "    for num_target in args.num_target:\n",
    "        predicted =  outputs[num_target].float()\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = criterion(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "        l1loss = nn.L1Loss()\n",
    "        MAE = l1loss(predicted, y_true[num_target].float().unsqueeze(1))\n",
    "        y_var = torch.var(y_true[num_target])\n",
    "        r_square = 1 - (loss / y_var)\n",
    "        test_acc[num_target].append(r_square.item())\n",
    "        confusion_matrices = None\n",
    "\n",
    "result = {'test_acc':test_acc,'MAE':MAE}\n",
    "\n",
    "print(f\"Test result: {test_acc} & {MAE} for {args.load}\") \n",
    "\n",
    "if confusion_matrices != None:\n",
    "    result['confusion_matrices'] = confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db644339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hi():\n",
    "    print(a)\n",
    "    def wow():\n",
    "        print('wow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d211cd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe553d94eb0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "858ffff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sum(y_true['age'].flatten())/len(y_true['age'])\n",
    "v=sum((y_true['age'].flatten()-m)**2)/len(y_true['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2788941e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.2458, dtype=torch.float64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(abs(y_true['age']-outputs['age'].flatten()))/1137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "78d80090",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0473, dtype=torch.float64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-loss/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "1c63edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "to=pd.read_csv(\"/scratch/connectome/3DCNN/data/1.ABCD/4.demo_qc/ABCD_phenotype_total.csv\")\n",
    "ad=pd.read_csv(\"/scratch/connectome/3DCNN/data/1.ABCD/4.demo_qc/ABCD_ADHD.csv\")\n",
    "con=pd.read_csv(\"/scratch/connectome/3DCNN/data/1.ABCD/4.demo_qc/ABCD_suicide_control.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c7ef348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2506, 118) (3108, 45)\n"
     ]
    }
   ],
   "source": [
    "print(ad.shape,con.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0f6583a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NDARINV89B7M962\n",
       "1    NDARINV6ZU9NKBV\n",
       "2    NDARINVLPMG7ZFU\n",
       "dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "images = glob.glob('/scratch/connectome/3DCNN/data/1.ABCD/3.2.FA_warpped_nii/*')\n",
    "images_subjectkeys=pd.Series(map(lambda x: x.split(\"/\")[-1].split(\".\")[0],images))\n",
    "images_subjectkeys[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13d8cfa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unspecified.Attention.Deficit.Hyperactivity.Disorder.x\n",
      "Attention.Deficit.Hyperactivity.Disorder.x\n"
     ]
    }
   ],
   "source": [
    "for c in con.columns:\n",
    "    if 'Attention' in c:print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ad3272b4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sjk=pd.concat([ad.subjectkey,con.subjectkey]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ffc9a235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdf=to[to.subjectkey.isin(sjk)==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "989cb445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     3993\n",
       "False    1621\n",
       "Name: subjectkey, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.subjectkey.isin(images_subjectkeys).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7f6e4b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NDARINVBZJGG4AN\n",
       "1    NDARINVXPZGM0LG\n",
       "2    NDARINVU9C36KFY\n",
       "dtype: object"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images2 = glob.glob('/scratch/connectome/3DCNN/data/1.ABCD/2.sMRI_freesurfer/*')\n",
    "images_subjectkeys2=pd.Series(map(lambda x: x.split(\"/\")[-1].split(\".\")[0],images2))\n",
    "images_subjectkeys2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8916fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2255\n",
       "1.0    1736\n",
       "Name: Attention.Deficit.Hyperactivity.Disorder.x, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smris=newdf[newdf.subjectkey.isin(images_subjectkeys2)==True]\n",
    "swithd=smris[smris.subjectkey.isin(images_subjectkeys)==True]\n",
    "swithd['Attention.Deficit.Hyperactivity.Disorder.x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d8cb626b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    2181\n",
       "2.0    1803\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swithd.sex.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
